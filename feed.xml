<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Herbie Bradley</title>
    <description>A machine learning, computer science, and maths blog</description>
    <link>https://herbiebradley.com/</link>
    <atom:link href="https://herbiebradley.com/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 27 Aug 2025 02:23:04 +0100</pubDate>
    <lastBuildDate>Wed, 27 Aug 2025 02:23:04 +0100</lastBuildDate>
    <generator>Jekyll v4.4.1</generator>
    
      <item>
        <title>OpenELM</title>
        <description>&lt;p&gt;&lt;em&gt;Crossposted from &lt;a href=&quot;https://carper.ai/openelm-release/&quot;&gt;CarperAI Blog&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://carper.ai/&quot;&gt;CarperAI&lt;/a&gt; is releasing &lt;a href=&quot;https://github.com/CarperAI/OpenELM&quot;&gt;OpenELM&lt;/a&gt;, an open-source library combining large language models with evolutionary algorithms for code synthesis!&lt;/p&gt;

&lt;p&gt;ELM stands for &lt;a href=&quot;https://arxiv.org/abs/2206.08896&quot;&gt;Evolution Through Large Models&lt;/a&gt;, a technique from a recent OpenAI paper demonstrating that large language models can act as intelligent mutation operators in an evolutionary algorithm, enabling diverse and high quality generation of code in domains not seen in the language model’s training set.&lt;/p&gt;

&lt;p&gt;The initial release of OpenELM, version 0.0.1, includes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;An implementation&lt;/strong&gt; of the basic ELM setup, including MAP-Elites for generated code, either from a diff model or from prompt engineering an existing language model.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The &lt;strong&gt;Sodarace 2D environment&lt;/strong&gt;, along with several other baseline environments.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A &lt;strong&gt;sandbox&lt;/strong&gt; using gVisor with a Docker container and Flask to safely run code generated by language models.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Benchmarking&lt;/strong&gt; of mutation LLMs using a toy environment.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In addition, we are also releasing &lt;a href=&quot;https://huggingface.co/CarperAI/diff-codegen-350m&quot;&gt;an open-source diff model&lt;/a&gt; fine-tuned on GitHub diffs from Salesforce’ CodeGen 350M code synthesis model, under an MIT license. A diff model is an autoregressive language model trained on edits to a piece of code, formatted in &lt;a href=&quot;https://en.wikipedia.org/wiki/Diff#Unified_format&quot;&gt;Unified Diff Format&lt;/a&gt;. These diff models can suggest, given a section of code and a description of the desired change (like a commit message), an intelligent change to the code that fits the description, marking the lines added, changed, and deleted in diff format. This diff model will let you more easily generate intelligent code suggestions in ELM.&lt;/p&gt;

&lt;p&gt;If you are interested in joining the OpenELM project, check out our &lt;a href=&quot;https://discord.gg/canadagoose&quot;&gt;Discord&lt;/a&gt; or &lt;a href=&quot;https://twitter.com/carper.ai&quot;&gt;Twitter&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Find out more about how it works below!&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&quot;evolutionary-algorithms-and-open-endedness&quot;&gt;Evolutionary algorithms and open-endedness&lt;/h1&gt;

&lt;p&gt;Evolutionary algorithms (EAs) are a type of population based optimization algorithm inspired by biological evolution. These algorithms start with a population of potential solutions to a problem (often called “individuals”), and then apply evolutionary operators such as mutation, crossover, and selection to the population, in order to generate new populations of solutions.&lt;/p&gt;

&lt;p&gt;Over time, the average quality of the solutions in the population will increase, as the “fittest” individuals are more likely to be selected for reproduction, and their offspring will inherit their “fitness”. Evolutionary algorithms therefore rely on a pre-defined fitness function which evaluates the performance or quality of an individual in the population.&lt;/p&gt;

&lt;p&gt;This search technique is gradient free and makes very few assumptions about the structure of the fitness landscape, making evolutionary algorithms a powerful optimizer for domains where fitness can be efficiently evaluated and the evolutionary operators can explore the search space effectively.&lt;/p&gt;

&lt;p&gt;One fundamental open problem in the evolutionary algorithms community is that of &lt;a href=&quot;https://www.oreilly.com/radar/open-endedness-the-last-grand-challenge-youve-never-heard-of/&quot;&gt;open-endedness&lt;/a&gt;. This field seeks to create algorithmic systems that produce never-ending innovation—just as biological evolution is capable of seemingly endless creativity and complexity. Of course, true endless innovation seems out of reach for AI for the foreseeable future, but creating open-ended artifacts of greater and greater complexity has the potential to unlock powerful new generative algorithms. Crucially, open-endedness requires the ability to search outside of the distribution of previous experience, which is typically difficult for deep learning models to do. A recent paper from OpenAI called &lt;a href=&quot;https://arxiv.org/abs/2206.08896&quot;&gt;Evolution Through Large Models (ELM)&lt;/a&gt; enables a step in this direction and explores the links between evolutionary algorithms and large language models (LLMs).&lt;/p&gt;

&lt;h1 id=&quot;elm--evolutionary-algorithms--llms&quot;&gt;ELM = evolutionary algorithms + LLMs&lt;/h1&gt;

&lt;p&gt;In a nutshell, ELM is a way to combine evolutionary algorithms and large language models for generation of diverse data.&lt;/p&gt;

&lt;p&gt;Evolutionary algorithms provide a way to generate diverse and novel data by making mutations and changes to candidates in the domain of interest, such as code. Language models provide a way to encode human knowledge to guide these mutations intelligently. Combining these two techniques therefore allows the search procedure to say on the “manifold of functionality” and lets the language model drive the evolutionary algorithm towards areas of the solution space that neither technique could find on their own.&lt;/p&gt;

&lt;p&gt;To set the scene a little bit, there have been numerous papers in the past year or two using large language models (LLMs) for code generation and synthesis, including OpenAIs &lt;a href=&quot;https://arxiv.org/abs/2107.03374&quot;&gt;Codex&lt;/a&gt; and DeepMind’s &lt;a href=&quot;https://www.deepmind.com/blog/competitive-programming-with-alphacode&quot;&gt;AlphaCode&lt;/a&gt;. Several of these papers, such AlphaCode, have focused on ways to generate code for specific domains including programming puzzles and solutions. However, sometimes the domain we want to generate code for has limited data that is only rarely found or not found in the training distribution. In this case, attempting to generate high quality code with prompt engineering will usually be impractical.&lt;/p&gt;

&lt;p&gt;ELM demonstrates that by incentivising diversity in program generation, we can create code in domains not in the training dataset using only a single seed program.&lt;/p&gt;

&lt;h1 id=&quot;how-elm-works&quot;&gt;How ELM works&lt;/h1&gt;

&lt;p&gt;ELM consists of three primary components: a mutation operator in the form of an LLM, an evolutionary algorithm that uses the LLM to create a diverse space of candidate solutions, and a way to fine-tune the LLM using its previously generated data.&lt;/p&gt;

&lt;p&gt;The first component consists of a &lt;strong&gt;diff model&lt;/strong&gt;—a model trained on git diffs to suggest, given a section of code and a commit message, a diff describing a modification to the code. This model allows us to start with a single seed program and output a variety of diverse alternative programs in the same domain, for use in the evolutionary algorithm.&lt;/p&gt;

&lt;p&gt;For the second component, we use the &lt;a href=&quot;https://arxiv.org/abs/1504.04909&quot;&gt;MAP-Elites&lt;/a&gt; evolutionary algorithm. It is a so-called quality-diversity algorithm, which works via generating a grid of niches called a behavior space spanning the space of possible solutions. When each candidate solution is generated, we evaluate its fitness and compare it against the current candidate in the corresponding grid cell—if it is better than it is placed into the grid cell. Over time, this map fills up with both high performing and diverse solutions.&lt;/p&gt;

&lt;p&gt;The third and final component is to fine-tune the language model to improve its performance further. Because candidate solutions from the diff model are in the form of a diff, we can fine-tune our model using the data in the MAP-Elites grid, which we have already selected to have high fitness and diversity. In addition, we can also further fine-tune our model using reinforcement learning to invent solutions conditionally depending on some property of the environment.&lt;/p&gt;

&lt;p&gt;Taken together, ELM shows a path forward for a creative loop of generating arbitrary open-ended data with a language model in domains not seen in the training set, followed by fine-tuning this language model on the generated data to further enhance its capabilities.&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;/assets/img/2022/elm_loop.png&quot; /&gt;&lt;figcaption class=&quot;maincolumn-figure&quot;&gt;A schematic of the basic ELM setup with MAP-Elites for the Sodaracer environment. In each iteration, a Python program is sampled from the map, the diff model creates an intelligent mutation, and the generated program is placed back into the map if it is better than the current program in that niche.&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h1 id=&quot;what-makes-a-good-elm-environment&quot;&gt;What makes a good ELM environment?&lt;/h1&gt;

&lt;p&gt;&lt;label for=&quot;mn-id&quot; class=&quot;margin-toggle&quot;&gt;⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;mn-id&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote-right&quot;&gt;&lt;img class=&quot;fullwidth&quot; src=&quot;/assets/img/2022/sodaracer.png&quot; /&gt;&lt;br /&gt;An example Sodaracer robot, consisting of masses and springs (muscles) connecting them. The objective in this domain is to design a robot which effectively travels across the terrain.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;The ELM paper and the OpenELM library implement several different baseline environments to play with. The primary domain used in the paper is the &lt;strong&gt;Sodarace&lt;/strong&gt; environment—a 2D physics-based simulation of robots moving across a variety of terrains. These robots are fully specified by a dictionary determining their joints, muscles, and size, but this dictionary is itself generated by the Python programs generated by the diff model. In this way, we can use ELM to generate diverse and high performing robots in the Sodarace environment, bootstrapped from a single seed program.&lt;/p&gt;

&lt;p&gt;We also implement a toy environment for image generation, in which ELM is tasked with generating programs which in turn create images matching a test image. Good domains to apply ELM have a high potential for open-ended and arbitrary complexity in generated artifacts, and the ability to evaluate fitness or performance relatively easily. For example, we might apply ELM to generation of programs with particular properties, such as solutions to programming puzzles, or to code which can generate design specifications.&lt;/p&gt;

&lt;p&gt;By releasing this open-source package for ELM we hope to encourage more research into the use of large language models with evolutionary algorithms, which has the potential to enable a new type of more sample-efficient evolutionary computing. By bringing together the evolutionary algorithm community and the language model community we can allow for the potential of both to be fully realised.&lt;/p&gt;
</description>
        <pubDate>Fri, 25 Nov 2022 10:00:00 +0000</pubDate>
        <link>https://herbiebradley.com/posts/openelm/</link>
        <guid isPermaLink="true">https://herbiebradley.com/posts/openelm/</guid>
        
        <category>Computer Science</category>
        
        <category>AI</category>
        
        <category>Deep Learning</category>
        
        
      </item>
    
      <item>
        <title>The Lottery Ticket Hypothesis</title>
        <description>&lt;p&gt;The Lottery Ticket Hypothesis is an interesting 2019 paper by Jonathan Frankle and Michael Carbin at MIT that attempts to explain the generalisation capability of deep neural networks, and identify situations where a smaller network can be trained to a similar accuracy as a large network. I recently presented this paper for a class and decided to post an extended version of my presentation here.&lt;/p&gt;

&lt;h2 id=&quot;motivation&quot;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;Deep neural networks are usually highly over-parameterized, containing numerous redundant connections. In other words, in most neural networks the number of parameters is significantly larger than the amount of training data. Empirically, over-parameterization improves optimization speed and generalisation, despite the fact that traditional learning theory says over-parameterization is a recipe for overfitting. However, there have been several attempts to train a network, then keep the “important” connections in the network while stripping away the rest, to improve the computational cost of inference. This technique is called pruning. Typically, a pruning algorithm consists of applying some heuristic to identify redundancies in the weights of a large pre-trained model, such as removing the connections with the smallest weights. The pruned network is then fine-tuned to learn better weights for the remaining connections and compensate for accuracy loss from removing connections.&lt;/p&gt;

&lt;p&gt;Recent studies have shown that the connections in a DNN can be pruned by as much as &lt;strong&gt;90%&lt;/strong&gt; without reducing test accuracy. However, naively attempting to re-initialize and train a pruned network from scratch gives worse performance than training a larger network and then pruning it. This paper attempts to answer the question of why this happens and propose techniques for identifying situations in which a pruned network will have high accuracy.&lt;/p&gt;

&lt;h2 id=&quot;the-hypothesis&quot;&gt;The Hypothesis&lt;/h2&gt;

&lt;p&gt;The authors propose the &lt;strong&gt;Lottery Ticket Hypothesis&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;A randomly-initialized, dense neural network contains a subnetwork that is initialized such that - when trained in isolation - it can match or exceed the test accuracy of the original network after training for at most the same number of iterations.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;To break this down: the subnetwork is a binary mask applied to the initial random parameters. When trained alone with its initialized parameters, this subnetwork can reach an accuracy at least as high as the original network in the same or fewer training iterations. This subnetwork is the winning “lottery ticket” - in this analogy, training a large network is like buying many lottery tickets, which gives a higher chance of “winning”: getting a high accuracy on the task. Almost all possible subnetworks are losing tickets, however the larger the network, the higher the chances that a winning ticket exists.&lt;/p&gt;

&lt;p&gt;The paper shows that subnetworks can be found by training a network, removing \(p%\) of the smallest magnitude parameters by fixing their value at 0, then resetting the remaining parameters to their initial values, creating the winning ticket. This is called one-shot pruning - the authors also found that iterative pruning, in which this process is repeated and \(p^\frac{1}{n}\) parameters are pruned over n rounds, creates smaller and equally accurate winning tickets than one-shot pruning.&lt;/p&gt;

&lt;h2 id=&quot;experiments-and-results&quot;&gt;Experiments and Results&lt;/h2&gt;

&lt;p&gt;The authors used this procedure to identify winning tickets with fully connected networks on the MNIST dataset, and with convolutional networks on the CIFAR10 image classification dataset. The pruned networks can be as small as &lt;strong&gt;3.6%&lt;/strong&gt; of the size of the original (usually 10-20%), but achieve at least as good accuracy in the same training time. In some cases, the winning ticket networks reach higher test accuracy than the original in a shorter training time.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2020/lotteryresults.jpg&quot; alt=&quot;Results on ResNet&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Crucially, when the winning tickets are randomly reinitialized rather than being trained with their original weights, their performance is far worse than the original network. This indicates that the pruned network architecture by itself does not ensure a subnetwork will be a winning ticket - the initialization AND the architecture form the sucessful subnetwork.&lt;/p&gt;

&lt;p&gt;The paper also shows that the reason winning tickets are successful is not because their initializations are close to their final values after training, as might be suspected, since the weights of winning tickets change more during training than other parameters. The authors suspect winning tickets may simply be initialized in an area of the loss landscape that is particularly conducive for optimization.&lt;/p&gt;

&lt;h2 id=&quot;a-final-conjecture&quot;&gt;A Final Conjecture&lt;/h2&gt;

&lt;p&gt;The authors then arrive at a conjecture (that they do not attempt to prove): &lt;em&gt;SGD seeks out and trains a subset of well-initialized weights.&lt;/em&gt; As a result, larger networks are easier to train from scratch, because there are more possible subnetworks that might be winning tickets.&lt;/p&gt;
</description>
        <pubDate>Thu, 30 Jan 2020 10:00:00 +0000</pubDate>
        <link>https://herbiebradley.com/posts/The-Lottery-Ticket-Hypothesis/</link>
        <guid isPermaLink="true">https://herbiebradley.com/posts/The-Lottery-Ticket-Hypothesis/</guid>
        
        <category>Computer Science</category>
        
        <category>AI</category>
        
        <category>Deep Learning</category>
        
        
      </item>
    
      <item>
        <title>Neuroevolution of Augmenting Topologies</title>
        <description>&lt;p&gt;A few months ago in the Spring I presented the 2002 paper &lt;a href=&quot;http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf&quot; title=&quot;NEAT&quot;&gt;Evolving Neural Networks through Augmenting Topologies (NEAT)&lt;/a&gt; for a class, so I thought I should make a blog post summarising this popular algorithm for evolving the architecture of neural networks.&lt;/p&gt;

&lt;p&gt;To set the scene, at the time NEAT came out the approach of evolving the weights of neural networks had shown promise for benchmarks such as pole balancing. These days problems like this are usually solved using non evolutionary deep reinforcement learning techniques. Before NEAT, several papers had tried evolving the topology of networks but were not able to outperform a fixed network. NEAT was the first algorithm to do so, which is why it is frequently used and very well known.&lt;/p&gt;

&lt;p&gt;The authors identified 3 key problems that would need to be solved:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;How should we encode network architectures to allow for crossover between topologies?&lt;/li&gt;
  &lt;li&gt;If we have an evolved topology that needs several generations to optimise, how can we protect that innovation and stop it from disappearing?&lt;/li&gt;
  &lt;li&gt;How can we minimise the complexity of topologies throughout evolution?&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;genetic-encoding&quot;&gt;Genetic encoding&lt;/h2&gt;

&lt;p&gt;Any encoding for network architectures will fall into one of two categories, direct or indirect. A direct encoding will describe everything about an individual network - each gene will describe a node or connection in the network. An indirect encoding tends to specify the processes for creating an individual network. As a result they are more compressed and the algorithm can compute each generation faster, but if not designed carefully they can focus the search on suboptimal network topologies, creating a bias in the search space.&lt;/p&gt;

&lt;p&gt;The main issue with encoding neural networks as genes is the competing conventions problem: having more than one way to represent the same network. When two genomes representing the same network structure do not have the same encoding, crossover is likely to produce damaged offspring. The key insight in NEAT’s encoding is that two genes with the same historical origin represent the same structure. We can mark genes according to their history by including a global “innovation number” for each edge in the network graph, essentially a version number for each edge.&lt;/p&gt;

&lt;p&gt;The NEAT encoding scheme is designed to allow corresponding genes to be easily matched up during crossover.  Each genome is a list of connection genes representing edges in the graph, each of which refers to two node genes (see header image). The connection genes specify the in node, out node, weight of the edge, whether or not the edge is in the graph, and the innovation number. So the genome (or genotype) is the list of connection genes and node genes, and the phenotype is the neural network diagram.&lt;/p&gt;

&lt;p&gt;There are two possible mutations to a genome: adding a node or adding a connection. When any connection is added, the global innovation number is incremented and assigned to that gene. Therefore the innovation numbers represent a history of every gene in the system.&lt;/p&gt;

&lt;h2 id=&quot;protecting-innovation&quot;&gt;Protecting innovation&lt;/h2&gt;

&lt;p&gt;In a topology evolving network, adding new structure usually causes the fitness of a network to decrease, since adding a new connection (for example) causes the fitness to reduce temporarily before the connection’s weight has a chance to optimise. Several generations may be required to optimise new structure and make use of it. NEAT solves this by dividing the population into species based on topological similarity, so individuals compete with others in their own species and have a chance to optimise before they have to compete with the overall population.&lt;/p&gt;

&lt;p&gt;NEAT uses the innovation numbers to determine topological similarity, by calculating a compatibility distance between two genomes. This is based on the number of connection genes with different innovation numbers in each genome, along with the average weight difference between connection genes that share the same innovation number. This distance measure allows us to divide the population of genomes into species using a threshold. Genomes are tested sequentially - if a genome’s distance to a randomly chosen member of a species is less than the threshold then it is placed into this species, ensuring species do not overlap.&lt;/p&gt;

&lt;p&gt;As a reproduction mechanism, NEAT uses fitness sharing, where all organisms in the same species share their fitness. The original fitness for each genome is adjusted by dividing by the number of individuals in the species. Species then grow or shrink depending on how high their average adjusted fitness is. Species reproduce by first eliminating the lowest performing members, then the entire population is replaced by the offspring of the remaining organisms in each species.&lt;/p&gt;

&lt;h2 id=&quot;minimizing-dimensionality&quot;&gt;Minimizing dimensionality&lt;/h2&gt;

&lt;p&gt;Typically, topology evolving networks start with an initial population of random topologies. However, a random population has a large amount of network structure that has not been evaluated for fitness and may be completely unnecessary. Therefore, with random initialisation the algorithm may waste effort by optimising unnecessarily complex structures. NEAT’s solution to this is to start with a uniform population of networks with zero hidden nodes. New structure is introduced incrementally with mutations, and the only structures that survive are found to be useful via fitness evaluations.&lt;/p&gt;

&lt;p&gt;Hence NEAT minimises the complexity of not only the final network, but all intermediate networks along the way. This significantly reduces the number of generations needed to find a solution.&lt;/p&gt;

&lt;h2 id=&quot;experiments--results&quot;&gt;Experiments &amp;amp; Results&lt;/h2&gt;

&lt;p&gt;In the NEAT paper, the algorithm was tested on single and double pole balancing tasks - a benchmark in which one or two poles are connected to a moving cart by a hinge. The objective is to move the cart left or right to keep the poles upright. NEAT was tested against two rival algorithms, Cellular Encoding, which evolves network structure, and Enforced Subpopulations, which only evolves weights. Two versions of this test were run - first allowing the network to see the cart velocity, and then hiding this information. In both tasks NEAT proved to be much more efficient than the rival algorithms. In the harder task with velocity hidden, NEAT used 25 times fewer evaluations to reach a solution than Cellular Encoding, 5 times fewer evaluations than Enforced Subpopulations, and never needed to restart. Hence NEAT showed a significant performance advantage over previous neuroevolutionary algorithms.&lt;/p&gt;

&lt;p&gt;NEAT was also evaluated with an ablation study - a study in which different components of the system are removed in turn to see which components are critically important. These experiments used the single pole balancing task, and tested NEAT with no growth of the topology, a random initial population rather than starting from a population with no hidden units, and a version without species. All showed worse results than the full version of NEAT, proving that all components of the algorithm are important for its performance.&lt;/p&gt;

&lt;h2 id=&quot;discussion&quot;&gt;Discussion&lt;/h2&gt;

&lt;p&gt;One thing NEAT demonstrates is that it is not the ultimate structure of the evolved network that really matters, but rather the structure of all the intermediate networks along the way to finding the solution. The connectivity of every intermediate solution represents a parameter space that evolution must optimize, and the more connections there are, the more parameters need to be optimized. Therefore, if the amount of structure can be minimized throughout evolution, so can the dimensionality of the spaces being explored, leading to significant performance gains. By starting simple and evolving the network as it becomes incrementally more complex, each increase in complexity resulting from new structure leads to a promising part of a higher dimensional space because most of the existing structure is already optimized.&lt;/p&gt;

&lt;p&gt;The NEAT algorithm is interesting on its own, but there are also several effective variants of the algorithm including &lt;a href=&quot;http://axon.cs.byu.edu/~dan/778/papers/NeuroEvolution/stanley3**.pdf&quot; title=&quot;HyperNEAT&quot;&gt;HyperNEAT&lt;/a&gt;, which is designed to produce large scale networks by evolving repeated patterns and structures.&lt;/p&gt;

&lt;p&gt;I hope this post was informative - I intend to make more posts very soon covering some deep learning models I have been studying.&lt;/p&gt;

</description>
        <pubDate>Sun, 22 Sep 2019 10:00:00 +0100</pubDate>
        <link>https://herbiebradley.com/posts/Neuroevolution-of-Augmenting-Topologies/</link>
        <guid isPermaLink="true">https://herbiebradley.com/posts/Neuroevolution-of-Augmenting-Topologies/</guid>
        
        <category>Computer Science</category>
        
        <category>AI</category>
        
        
      </item>
    
      <item>
        <title>The Keele University Prime</title>
        <description>&lt;p&gt;Last year, the YouTube channel Numberphile &lt;a href=&quot;https://www.youtube.com/watch?v=fQQ8IiTWHhg&quot; title=&quot;The Trinity Hall Prime&quot;&gt;published a video&lt;/a&gt; showing a prime number of 1350 digits that looks like the coat of arms of Trinity Hall College, Cambridge. The number 1350 is significant, since it is the year the college was founded.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2018/trinity-hall-prime.jpg&quot; alt=&quot;The Trinity Hall Prime&quot; /&gt;&lt;/p&gt;

&lt;p&gt;After coming across this video, I decided to try and make a similar number for Keele University (founded in 1949):&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2018/combinedprime.jpg&quot; alt=&quot;Keele University Prime&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;how-did-i-make-this&quot;&gt;How did I make this?&lt;/h2&gt;

&lt;p&gt;I found several scripts around the internet to generate prime numbers from pictures, but none of them gave a good looking result so I decided to make the logo art manually. I estimated that the best size for the number was 40 columns x 48 rows, leaving a 49th row of 13 digits to make up the total of 1949 digits. Then I spent about four hours flipping the digits to get the best looking logo.&lt;/p&gt;

&lt;p&gt;Next, I wrote a Python script to iterate over three digits in the middle of the bottom row and test each possibility with the Miller-Rabin probabilistic primality test. On my laptop, this computation took only a few minutes to check all 1000 combinations, and returned one possible number which was very likely to be prime. Finally, I used the &lt;a href=&quot;https://www.alpertron.com.ar/ECM.HTM&quot; title=&quot;Integer Factorization Tool&quot;&gt;tool on Dario Alpern’s website&lt;/a&gt; to make sure that the Miller-Rabin test was correct, and the number actually was prime.&lt;/p&gt;

&lt;p&gt;I also tried iterating over a few other three digit sequences in the number and found several primes there too, but I decided the prime shown above looked the best. &lt;a href=&quot;https://gist.github.com/herbiebradley/d31e87ebf1e4c325a2658ed1df21f171&quot; title=&quot;Prime Search - Python&quot;&gt;The script I used is here.&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;how-does-this-work&quot;&gt;How does this work?&lt;/h2&gt;

&lt;p&gt;By the prime number theorem, there are approximately \(\frac{n}{\log n}\) primes less than \(n\). Hence there are approximately&lt;/p&gt;

\[\frac{10^{1949}}{\log 10^{1949}} - \frac{10^{1948}}{\log 10^{1948}} \approx 2.005 \times 10^{1945}\]

&lt;p&gt;primes of 1949 digits. There are \(4.5 \times 10^{1948}\) odd numbers of 1949 digits, so approximately one in every 2244 numbers I check is prime. This is why iterating over a three digit sequence is a reasonable thing to do, since you are quite likely to hit a prime in the first or second three digit sequence you try. In the Trinity Hall prime you can see a place where the author also looped over a sequence of three digits.&lt;/p&gt;

</description>
        <pubDate>Tue, 18 Dec 2018 10:00:00 +0000</pubDate>
        <link>https://herbiebradley.com/posts/the-keele-university-prime/</link>
        <guid isPermaLink="true">https://herbiebradley.com/posts/the-keele-university-prime/</guid>
        
        <category>Number Theory</category>
        
        <category>Maths</category>
        
        <category>Python</category>
        
        <category>Keele</category>
        
        
      </item>
    
  </channel>
</rss>
